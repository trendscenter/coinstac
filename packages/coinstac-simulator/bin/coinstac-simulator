#!/usr/bin/env node

'use strict';

const util = require('util');
const readFile = util.promisify(require('fs').readFile);
const writeFile = util.promisify(require('fs').writeFile);
const program = require('commander');
const inquirer = require('inquirer');
const glob = util.promisify(require('glob'));
const path = require('path');
const winston = require('winston');
const fs = require('fs');

const pkg = require('../package.json');

const logger = winston.createLogger({
  level: 'info',
  transports: [
    new winston.transports.Console({ format: winston.format.cli() }),
  ],
});

let DEBUG_MODE = process.execArgv.includes('--inspect-brk=9229');

process.on('unhandledRejection', (error) => {
  logger.error(`unhandledRejection: ${error.stack}`); // eslint-disable-line no-console
  process.exit(1);
});

program
  .version(pkg.version)
  .option('-i, --inputspec [path]', '/path/to/inputSpec, defaults to ./test/inputspec.json, will interactively create one if none found')
  .option('-s, --compspec [path]', '/path/to/compSpec optional, defaults to cwd')
  .option('-c, --clientNumber [number]', 'number of clients, defaults to 1 not included the remote in decentralized mode. In local mode this creates separate runs')
  .option('-d, --directory [path]', ' path to where input, output, and cache is stored. Defaults to ./test/[input|cache|output]')
  .option('-t, --showinput', ' on errors show comp input that computation failed with')
  .option('-e, --debug', ' enter debug mode, displays extra info including input')
  .option('-p, --pipeline [path]', ' give a pipeline file to run a full pipeline from, working dir used is first comp listed')
  .option('-u, --upload', ' upload computation spec')
  .option('--username [username]', ' username for uploads')
  .option('--password [password]', ' password for uploads')
  .option('--loglevel [level]', ' enter info, debug, and silly log levels')
  .option('--preprocess', 'preprocess');

program.on('--help', () => {
  logger.info([ // eslint-disable-line
    '\n',
    '\tTest a computation in a COINSTAC simulated environment.\n\n',
    '\tThe simulator is meant to run in your computation\'s directory',
    '\tand requires a valid compspec and with the specified docker image\n',
    '\tin your docker image library.\n\n',
    '\tIf you do not have an input map for your computation, a prompt will.\n',
    '\tguide you through creating one.\n\n',
    '\tFurther help can be found in the Readme:\n',
    '\thttps://github.com/MRN-Code/coinstac/blob/master/packages/coinstac-simulator/README.md\n\n',
    '\tExample:\n\n',
    '\t  coinstac-sim -i ./inputSpec.json -c 2\n',
  ].join(' '));
});

program.parse(process.argv);

let globalMode = 'local';
const inSpecPath = program.directory ? path.join(program.directory, 'inputspec.json') : path.join('.', 'test', 'inputspec.json');

if (program.loglevel) {
  DEBUG_MODE = true;
  process.LOGLEVEL = program.loglevel;
  logger.level = process.LOGLEVEL;
} else if (DEBUG_MODE) {
  process.LOGLEVEL = 'debug';
  logger.level = 'debug';
}
// require after LOGLEVEL set
const sim = require('../src/');
const compUpload = require('../src/comspec-upload');
const { pullImages } = require('coinstac-manager'); // eslint-disable-line import/order
const { fetchPreprocessComputations, createInputSpec, prepareDirectory } = require('../src/preprocess');

async function runPipeline(pipelineSpec, operatingDirectory) {
  /* eslint-disable no-console */
  const count = program.clientNumber ? program.clientNumber // eslint-disable-line no-nested-ternary, max-len
    : (Array.isArray(pipelineSpec) ? pipelineSpec.length : 1); // eslint-disable-line no-nested-ternary, max-len
  logger.debug(`Starting ${globalMode} simulator run with ${count} client(s)`);

  const started = sim.startRun({
    spec: pipelineSpec,
    runMode: globalMode,
    clientCount: count,
    operatingDirectory: operatingDirectory || program.directory,

  });
  try {
    const simRun = await started;
    const results = await simRun.allResults;

    logger.info('Simulator run finished');
    if (globalMode === 'decentralized') {
      logger.info(`Decentralized results:\n ${JSON.stringify(results.locals[0], null, 2)}`);
    } else {
      logger.info('Local run(s) finished');
      results.locals.forEach((res, idx) => logger.info(`Client ${idx} results:\n${JSON.stringify(res, null, 2)}\n`));
    }
  } catch (err) {
    logger.error('Simulator run failed!');
    logger.error('Fun error details:\n');
    logger.error(err.message);
    logger.error(err.stack || '');
  }
  return started;
}

function pipelineSpecFactory(inputSpec, mode, comp) {
  let specMap = Array.isArray(inputSpec) ? inputSpec : [inputSpec];
  const comps = Array.isArray(comp) ? comp : [comp];
  specMap = specMap.map((spec, index) => ({
    inputMap: spec,
    controller: { type: mode[index] },
    computations: [comps[index]],
  }));
  return {
    steps: specMap,
  };
}

const startPreprocessRun = async (pipelineSpec, baseDir) => {
  await fs.promises.rm(path.join(baseDir, 'input'), { recursive: true, force: true });
  await prepareDirectory(pipelineSpec, baseDir);
  const run = await runPipeline(pipelineSpec, baseDir);
  // cleanup input dir
  await fs.promises.rm(path.join(baseDir, 'input'), { recursive: true, force: true });
  //  move dir to better store results
  const originalDir = path.join(baseDir, 'output', 'local0', 'simulatorRun');
  const destinationDir = path.join(baseDir, 'output', `preprocessedData-${new Date().toLocaleString('en-US').replace(/[ ,:/]/ig, '-')}`);
  await fs.promises.rename(
    originalDir,
    destinationDir
  );
  return run;
};

const promptGenerateAndPreprocess = async (pipelineSpecPath, baseDir) => {
  let rawSpec;
  try {
    rawSpec = fs.readFileSync(pipelineSpecPath);
  } catch (e) {
    logger.info('Pipeline spec not found, proceeding to generate one...');
    logger.info('If this is in error, make sure your spec is named \'pipelineSpec.json\'');
    rawSpec = null;
  }

  let pipelineSpec;
  if (rawSpec) {
    pipelineSpec = JSON.parse(rawSpec);
  }
  // authenticate and fetch computations
  const genSpecAndProcess = async (pipelineSpec, baseDir) => {
    const computations = await fetchPreprocessComputations(program.username, program.password);
    // list options of computations
    await inquirer.prompt([{
      type: 'number',
      name: 'select preprocess',
      message: `Select a preprocessing computation:\n${computations.map((computation, index) => {
        return `${index} ) ${computation.meta.name}`;
      }).join('\n\n')}${pipelineSpec ? '\n\n*** Note: this will rename your current pipelineSpec and create a new one ***' : ''}`,
    }]).then(async (answers) => {
      const answer = answers['select preprocess'];
      if (!Object.keys(computations).includes(answer)) {
        logger.info('The answer provided is not a valid choice.');
      } else {
        // download the selected computation
        const selectedComputation = computations[answer];
        const pullStreams = await pullImages([{
          img: selectedComputation.computation.dockerImage,
          compId: selectedComputation.id,
          compName: selectedComputation.meta.name,
        }]);

        logger.info('Downloading docker image...');
        await Promise.all(
          pullStreams.map((obj) => {
            return new Promise((resolve, reject) => {
              if (typeof obj.stream.pipe === 'function') {
                obj.stream.pipe(process.stdout);
                obj.stream
                  .on('end', () => { resolve(); })
                  .on('error', (error) => { reject(error); });
              } else {
                resolve();
                process.stdout.write('.');
              }
            });
          })
        );
        // find the .csv file
        const files = await new Promise((resolve, reject) => {
          fs.readdir('./', (err, data) => {
            if (err) {
              reject(err);
            }
            resolve(data);
          });
        });
        const csvs = files.filter((file) => {
          if (file.includes('.csv')) {
            return file;
          }
          return false;
        });
        if (csvs.length < 1) {
          logger.info('no .csv files found');
          process.exit(0);
        }
        await inquirer.prompt([{
          type: 'number',
          name: 'select covariates file',
          message: `Select Covariates File to use for pipeline:\n${csvs.map((csv, index) => {
            return `${index} ) ${csv}`;
          }).join('\n\n')}\n`,
        }]).then(async (answers) => {
          const answer = answers['select covariates file'];

          if (!Object.keys(csvs).includes(answer)) {
            logger.info('The answer provided is not a valid choice.');
            process.exit();
          } else {
            //  create an inputspec from the csv and the api results
            const baseInputSpec = JSON.parse(
              JSON.stringify(selectedComputation.computation.input)
            );
            const fulfilledInputSpec = createInputSpec(baseInputSpec, csvs[answer]);
            const generatedPipeSpec = pipelineSpecFactory(fulfilledInputSpec, ['local'], selectedComputation);
            if (pipelineSpec) fs.promises.rename('./pipelineSpec.json', `./pipelineSpec-${pipelineSpec.steps[0].computations[0].meta.id}-${new Date().toLocaleString('en-US').replace(/[ ,:/]/ig, '-')}.json`);
            fs.writeFileSync('pipelineSpec.json', JSON.stringify(generatedPipeSpec, null, 2));

            await inquirer.prompt([{
              type: 'confirm',
              name: 'noexit',
              message: 'pipelineSpec.json created\n\nIf you dont want to use default options\nPlease edit pipelineSpec.json manually\nProceed with pipeline?.',
            }]).then((resp) => {
              if (resp.noexit) {
                return startPreprocessRun(generatedPipeSpec, baseDir);
              }
              process.exit();
            });
          }
        });
      }
    });
  };

  if (!pipelineSpec) {
    await genSpecAndProcess(pipelineSpec, baseDir);
  } else {
    await inquirer.prompt([{
      type: 'confirm',
      name: 'run',
      message: `Preprocess using existing pipeline for ${pipelineSpec.steps[0].computations[0].meta.name}?`,
    }]).then(async (resp) => {
      if (resp.run) {
        return startPreprocessRun(pipelineSpec, baseDir);
      }
      // make new spec, ask to rename old
      await genSpecAndProcess(pipelineSpec, baseDir);
    });
  }
};


if (program.preprocess) {
  return promptGenerateAndPreprocess('./pipelineSpec.json', 'coinstac/')
    .then(() => process.exit(0));
}

if (program.upload) {
  if (!program.username && !program.password) {
    logger.error('Username and password required for compspec upload');
    process.exit(1);
  }
  logger.info('Uploading computation schema.');

  compUpload.compspecUpload(program.username, program.password, logger)
    .then(() => {
      process.exit();
    })
    .catch((e) => {
      logger.error(e.message);
      process.exit(1);
    });
} else {
  let fulfilledPipelineSpec;

  if (program.pipeline) {
    fulfilledPipelineSpec = readFile(program.pipeline)
      .then((pipeSpec) => {
        const compSpecs = JSON.parse(pipeSpec);
        const fileProm = compSpecs.reduce((memo, spec, index) => {
          const baseDir = path.dirname(path.resolve(path.dirname(program.pipeline), spec));
          memo.push(Promise.all([
            readFile(path.resolve(baseDir, spec))
              .then(file => JSON.parse(file)).catch(() => {
                throw new Error(`Incorrect json or missing file at ${path.resolve(baseDir, spec)}`);
              }),
            readFile(path.join(baseDir, 'test', index === 0 ? 'inputspec.json' : 'inputspec-pipeline.json'))
              .then(file => JSON.parse(file)).catch(() => {
                throw new Error(`Incorrect json or missing file at ${path.join(baseDir, 'test', index === 0 ? 'inputspec.json' : 'inputspec-pipeline.json')}`);
              }),
          ]));
          return memo;
        }, []);
        return Promise.all(fileProm)
          .then((fileGroups) => {
            // each group element is [0] compspec, [1] inputSpec
            // group compspecs and inputspecs into an object we can create pipepecs from
            const mode = fileGroups.reduce((memo, fileGroup) => {
              if (fileGroup[0].computation.remote) {
                memo.push('decentralized');
                globalMode = 'decentralized';
              } else {
                memo.push('local');
              }
              return memo;
            }, []);

            let clientCount;
            const groupedSpecs = fileGroups.reduce((memo, fileGroup, index) => {
              memo.compSpecs.push(fileGroup[0]);
              const inputSpec = Array.isArray(fileGroup[1]) ? fileGroup[1] : [fileGroup[1]];

              clientCount = clientCount || inputSpec.length;
              if (clientCount !== inputSpec.length) throw new Error('Mismached inputspec client count');

              inputSpec.forEach((spec, idx) => {
                if (memo.inputSpecs[idx]) {
                  memo.inputSpecs[idx][index] = spec;
                } else {
                  memo.inputSpecs[idx] = [spec];
                }
              });

              return memo;
            }, { compSpecs: [], inputSpecs: [] });

            const pipelineSpecs = groupedSpecs.inputSpecs.map((site) => {
              return pipelineSpecFactory(site, mode, groupedSpecs.compSpecs);
            });

            return pipelineSpecs;
          });
      });
  } else {
    fulfilledPipelineSpec = Promise.all([
      readFile(program.compspec ? program.compspec : 'compspec.json'),
      readFile(program.inputspec ? program.inputspec : inSpecPath),
    ].map(p => p.catch(error => error)))
      .then((specs) => {
        const comp = JSON.parse(specs[0]);
        globalMode = comp.computation.remote ? 'decentralized' : 'local';
        const mode = new Array(specs.length).fill(globalMode);
        /**
         * Create a spec via cmdline if none is given
         * @param  {Object} variable [description]
         * @param  {[type]} key      [description]
         * @return {[type]}          [description]
         */
        const createInputSpec = (variable, key) => {
          return inquirer.prompt({
            type: 'input',
            name: `${key}`,
            message: `Please give a ${variable.type} input for variable: ${key}
          Files can use glob paterns to resolve to multiple file paths from the input dir
          ie: **/*.txt`,
          }).then((value) => {
            return Promise.all([
              variable.type === 'files' ? glob(value[key]) : value[key],
            ]).then((resolvedVal) => {
              const coerce = variable.type === 'number' ? parseFloat(resolvedVal[0]) : resolvedVal[0];
              return {
                [key]: { value: coerce },
              };
            });
          });
        };

        let specProm;
        if (specs[1].code === 'ENOENT') {
          const memo = {};
          specProm = Object.keys(comp.computation.input).reduce((prom, variable) => {
            return prom.then(() => {
              return createInputSpec(comp.computation.input[variable], variable);
            }).then(res => Object.assign(memo, res));
          }, Promise.resolve())
            .then((res) => {
              return inquirer.prompt({
                type: 'confirm',
                name: 'write',
                message: `Write out the input spec just entered? This WILL overwrite any spec in
            ${inSpecPath}`,
              }).then((response) => {
                const prom = Promise.resolve(res);
                if (response.write) {
                  prom.then(res => writeFile(inSpecPath, JSON.stringify(res))
                    .then(res => res));
                }
                return prom;
              });
            });
        } else {
          specProm = JSON.parse(specs[1]);
        }

        return Promise.all([specProm])
          .then((inputSpec) => {
            let generatedPipeSpec;
            if (Array.isArray(inputSpec[0])) {
              generatedPipeSpec = inputSpec[0].map(spec => pipelineSpecFactory(spec, mode, comp));
            } else {
              generatedPipeSpec = pipelineSpecFactory(inputSpec[0], mode, comp);
            }

            return generatedPipeSpec;
          });
      });
  }

  fulfilledPipelineSpec
    .then((pipelineSpec) => {
      runPipeline(pipelineSpec);
    });
}
